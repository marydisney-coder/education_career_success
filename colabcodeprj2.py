# -*- coding: utf-8 -*-
"""disclassifi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14i60VHctZsYM9DltjEcUy1X4wSAsYiw1
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler,MinMaxScaler
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline

data = pd.read_csv("education_career_success.csv")
print(data.head())

print(data.isnull().sum())

data.duplicated().sum()

num_cols=data.select_dtypes(include=['int64','float64']).columns
print(num_cols)
cat_cols=data.select_dtypes(include=['object']).columns
print(cat_cols)
num_imputer=SimpleImputer(strategy='mean')
cat_imputer=SimpleImputer(strategy='most_frequent')
data[num_cols]==num_imputer.fit_transform(data[num_cols])
data[cat_cols]==cat_imputer.fit_transform(data[cat_cols])

def remove_outliers(data, column):
  Q1=data[column].qunatile(0.25)
  Q3=data[column].qunatile(0.75)
  IQR=Q3-Q1
  lower=Q1-1.5*IQR
  upper=Q3+1.5*IQR
  return data[(data[column])>=lower&(data[column])<=upper]
  data=remove_outliers(data,"Fare")

label_cols=['Current_Job_Level']
le=LabelEncoder()
for col in label_cols:
  data[col]=le.fit_transform(data[col])

data=pd.get_dummies(data,columns=[col for col in cat_cols if col not in label_cols])

scaler=StandardScaler()
data[num_cols]=scaler.fit_transform(data[num_cols])

corr = data.corr()
print(corr['Current_Job_Level'].sort_values(ascending=False))

median_RC=data['Current_Job_Level'].median()
RC_cat=data['Current_Job_Level'].apply(lambda x:'Mid' if x >= median_RC else 'entry')
RC_counts=RC_cat.value_counts()
plt.pie(RC_counts,labels=RC_counts.index.tolist(),autopct='%.f%%',shadow=True)
plt.title("job_level")
plt.show()

X = data.drop('Current_Job_Level', axis=1)
y =  data['Current_Job_Level']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
X, y, test_size = 0.3, random_state = 4)

print ('Train set:', X_train.shape, y_train.shape)
print ('Test set:', X_test.shape, y_test.shape)

#1. Logistic Regression
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print("Accuracy:", model.score(X_test, y_test))